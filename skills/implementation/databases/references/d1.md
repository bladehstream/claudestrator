# Cloudflare D1 Reference

D1 is Cloudflare's serverless SQLite database for edge applications.

## Overview

- **Engine**: SQLite (edge-optimized)
- **Max Size**: 10GB per database
- **Use Case**: Per-user, per-tenant, or per-entity databases
- **Pricing**: Usage-based (queries + storage)
- **Features**: Time Travel (30-day point-in-time recovery), automatic backups

## Setup

### Create Database

```bash
# Create D1 database
npx wrangler d1 create my-database

# List databases
npx wrangler d1 list

# Get database info
npx wrangler d1 info my-database
```

### Wrangler Configuration

```toml
# wrangler.toml
name = "my-worker"
main = "src/index.ts"
compatibility_date = "2024-01-01"

[[d1_databases]]
binding = "DB"
database_name = "my-database"
database_id = "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
```

### TypeScript Types

```typescript
// env.d.ts
interface Env {
  DB: D1Database;
}
```

## Basic Operations

### Query Execution

```typescript
export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    // Simple query
    const { results } = await env.DB.prepare(
      'SELECT * FROM users WHERE id = ?'
    ).bind(userId).all();
    
    // First result only
    const user = await env.DB.prepare(
      'SELECT * FROM users WHERE id = ?'
    ).bind(userId).first();
    
    // Run without results (INSERT, UPDATE, DELETE)
    const { meta } = await env.DB.prepare(
      'INSERT INTO users (name, email) VALUES (?, ?)'
    ).bind('Alice', 'alice@example.com').run();
    
    console.log('Changes:', meta.changes);
    console.log('Last Row ID:', meta.last_row_rowid);
    
    return Response.json(results);
  }
};
```

### Batch Operations

```typescript
// Execute multiple statements in a transaction
const results = await env.DB.batch([
  env.DB.prepare('INSERT INTO users (name) VALUES (?)').bind('Alice'),
  env.DB.prepare('INSERT INTO users (name) VALUES (?)').bind('Bob'),
  env.DB.prepare('SELECT * FROM users'),
]);

// results[0] - First INSERT result
// results[1] - Second INSERT result  
// results[2] - SELECT result
```

### Raw SQL Execution

```typescript
// Execute raw SQL (useful for DDL)
await env.DB.exec(`
  CREATE TABLE IF NOT EXISTS users (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    email TEXT UNIQUE NOT NULL,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
  );
  
  CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
`);
```

## Schema Management

### Create Tables

```sql
-- Via wrangler d1 execute
CREATE TABLE users (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name TEXT NOT NULL,
  email TEXT UNIQUE NOT NULL,
  metadata TEXT,  -- JSON stored as text
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE posts (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  title TEXT NOT NULL,
  content TEXT,
  author_id INTEGER NOT NULL REFERENCES users(id),
  published INTEGER DEFAULT 0,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_posts_author ON posts(author_id);
CREATE INDEX idx_posts_published ON posts(published) WHERE published = 1;
```

### Migrations with SQL Files

```bash
# Create migrations directory
mkdir -p migrations

# Create migration file
# migrations/0001_initial.sql
```

```sql
-- migrations/0001_initial.sql
CREATE TABLE users (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  email TEXT UNIQUE NOT NULL,
  name TEXT
);

-- migrations/0002_add_posts.sql
CREATE TABLE posts (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  title TEXT NOT NULL,
  author_id INTEGER REFERENCES users(id)
);
```

```bash
# Apply migrations
npx wrangler d1 migrations apply my-database

# Apply to local database
npx wrangler d1 migrations apply my-database --local
```

## Using with Drizzle ORM

### Setup

```bash
npm install drizzle-orm
npm install -D drizzle-kit
```

### Schema

```typescript
// src/db/schema.ts
import { sqliteTable, text, integer } from 'drizzle-orm/sqlite-core';

export const users = sqliteTable('users', {
  id: integer('id').primaryKey({ autoIncrement: true }),
  email: text('email').notNull().unique(),
  name: text('name'),
  createdAt: text('created_at').default(sql`CURRENT_TIMESTAMP`),
});

export const posts = sqliteTable('posts', {
  id: integer('id').primaryKey({ autoIncrement: true }),
  title: text('title').notNull(),
  content: text('content'),
  authorId: integer('author_id').notNull().references(() => users.id),
  published: integer('published', { mode: 'boolean' }).default(false),
});
```

### Drizzle Config

```typescript
// drizzle.config.ts
import { defineConfig } from 'drizzle-kit';

export default defineConfig({
  dialect: 'sqlite',
  schema: './src/db/schema.ts',
  out: './drizzle',
  driver: 'd1-http',
  dbCredentials: {
    accountId: process.env.CLOUDFLARE_ACCOUNT_ID!,
    databaseId: process.env.D1_DATABASE_ID!,
    token: process.env.CLOUDFLARE_API_TOKEN!,
  },
});
```

### Worker with Drizzle

```typescript
// src/index.ts
import { drizzle } from 'drizzle-orm/d1';
import * as schema from './db/schema';

export interface Env {
  DB: D1Database;
}

export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    const db = drizzle(env.DB, { schema });
    
    // Type-safe queries
    const users = await db.select().from(schema.users);
    
    const user = await db.query.users.findFirst({
      where: eq(schema.users.id, 1),
      with: { posts: true },
    });
    
    const [newUser] = await db.insert(schema.users)
      .values({ email: 'alice@example.com', name: 'Alice' })
      .returning();
    
    return Response.json(users);
  }
};
```

## JSON Handling

D1 uses SQLite, so JSON is stored as TEXT but has JSON functions.

```typescript
// Insert JSON
await env.DB.prepare(
  'INSERT INTO users (name, metadata) VALUES (?, ?)'
).bind('Alice', JSON.stringify({ preferences: { theme: 'dark' } })).run();

// Query JSON
const { results } = await env.DB.prepare(`
  SELECT 
    name,
    json_extract(metadata, '$.preferences.theme') as theme
  FROM users
  WHERE json_extract(metadata, '$.preferences.theme') = ?
`).bind('dark').all();
```

## Time Travel (Point-in-Time Recovery)

```bash
# List available restore points
npx wrangler d1 time-travel info my-database

# Restore to specific timestamp
npx wrangler d1 time-travel restore my-database --timestamp "2024-01-15T10:30:00Z"

# Restore to specific bookmark
npx wrangler d1 time-travel restore my-database --bookmark "00000001-00001234"
```

## Local Development

```bash
# Run worker with local D1
npx wrangler dev --local

# Execute SQL on local database
npx wrangler d1 execute my-database --local --command "SELECT * FROM users"

# Apply migrations locally
npx wrangler d1 migrations apply my-database --local
```

### Local Database Location

Local D1 databases are stored in:
```
.wrangler/state/v3/d1/
```

## Performance Tips

### Prepared Statements

```typescript
// ✅ Good - Prepared statement
const stmt = env.DB.prepare('SELECT * FROM users WHERE id = ?');
const user = await stmt.bind(userId).first();

// ❌ Avoid - String interpolation (SQL injection risk)
const user = await env.DB.prepare(
  `SELECT * FROM users WHERE id = '${userId}'`
).first();
```

### Batching

```typescript
// ✅ Batch multiple operations
await env.DB.batch([
  env.DB.prepare('INSERT INTO logs (action) VALUES (?)').bind('login'),
  env.DB.prepare('UPDATE users SET last_login = ? WHERE id = ?').bind(new Date().toISOString(), userId),
]);

// ❌ Don't execute sequentially
await env.DB.prepare('INSERT INTO logs...').run();
await env.DB.prepare('UPDATE users...').run();
```

### Indexes

```sql
-- Create indexes for frequently queried columns
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_posts_author_published ON posts(author_id, published);

-- Partial index for common filter
CREATE INDEX idx_published_posts ON posts(created_at) WHERE published = 1;
```

## Limitations

- **Single region**: Primary writes go to one location
- **SQLite limitations**: No stored procedures, limited concurrent writers
- **Size limit**: 10GB per database
- **Connection model**: HTTP-based, not persistent connections
- **No built-in full-text search**: Use FTS5 extension manually

## Best Practices

1. **Use prepared statements** - Prevents SQL injection, better performance
2. **Batch operations** - Reduce round trips
3. **Index appropriately** - SQLite query planner benefits from indexes
4. **Store JSON carefully** - Use `json_extract` for queries
5. **Design for scale-out** - Multiple smaller databases vs one large
6. **Test locally** - Use `--local` flag during development
7. **Leverage Time Travel** - For debugging and recovery
8. **Use Drizzle** - Type safety and better DX
